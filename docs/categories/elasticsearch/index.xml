<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Elasticsearch on focaaby&#39;s Note</title>
    <link>/categories/elasticsearch/</link>
    <description>Recent content in Elasticsearch on focaaby&#39;s Note</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/elasticsearch/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Managing Nginx log via Docker ELK Stack</title>
      <link>/blog/managing-nginx-log-via-docker-elk-stack/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/managing-nginx-log-via-docker-elk-stack/</guid>
      <description>前因 經常在 DevOps TW 看到分析管理 log 有那些套件可以使用，傳統來說彙整 log 會使用 RSYSLOG，而筆者想要嘗試的則是近幾年興起應用於 big data 的圖表分析 Elasticsearch + Logstash + Kibana，取每個元件字首簡稱 ELK Stack。
選用原因 主要筆者的環境需要將簡單將 syslog 或 Nginx acess_log 日誌檔案做基本處理，且具有 buffer 功能。 而 Logstash 就是具有以上功能並有 pipeline 分成三階段（inputs → filters → outputs）的概念：
 input：接受檔案、syslog（符合 RFC3164 標準）或像 Redis broker 當作輸入來源。 filter：grok 相似正規表示法，但較方便於將 log file 處理成想要的格式。 ouput：經過 filter 處理過的資料，輸出結果多樣。如：檔案、Elatcsearch、statsd 等。  動手做 筆者習慣利用 docker 來架設測試環境，當然也有已經整理好的 Docker ELK stack Github repo
啟用 ELK Stack git clone https://github.</description>
    </item>
    
  </channel>
</rss>